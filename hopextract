#!/bin/bash

# script for extracting various metadata from HoP HTML pages and preparing for Wikidata

# nb this needs them all in a handy directory at eg 1386-1421/member/xyz.html

# uses pup - https://github.com/ericchiang/pup

# refresh with 
# curl "https://raw.githubusercontent.com/generalist/wikidata-hop/master/hopextract" > hopextract

rm working/*

echo "1386-1421" > working/period
echo "1509-1558" >> working/period
echo "1558-1603" >> working/period
echo "1604-1629" >> working/period
echo "1660-1690" >> working/period
echo "1690-1715" >> working/period
echo "1715-1754" >> working/period
echo "1754-1790" >> working/period
echo "1790-1820" >> working/period
echo "1820-1832" >> working/period

# let's do this across all MPs, ever

rm educated

for j in `cat working/period` ; do

# produce a raw list of the educated section

for i in `ls $j/member/*.html` ; do echo -e $i "\t" `cat $i | pup --color | grep -A 2 "educ$" | tail -1` >> educated ; done
for i in `ls $j/member/*.html` ; do echo -e $i "\t" `cat $i | pup --color | grep -A 2 "educ.$" | tail -1` >> educated ; done
# these are the two forms used

done

# pull out the schools (just schools for now as proof of concept)
# drop them into single text files for now so that they can be manually reviewed

grep "Eton" educated > working/school-eton # Q192088
grep "Harrow" educated > working/school-harrow # Q1247373
grep "Rugby" educated > working/school-rugby # Q1143281
grep "Westminster" educated > working/school-westminster # Q1341516
grep "Winchester" educated > working/school-winchester # Q1059517

# now the colleges/universities

grep "Christ Church, Oxf" educated > working/coll-cc-ox # Q745967
# lots more Oxbridge to do, but these are very inconsistent - lots of variation

grep "Edinburgh Univ" educated > working/uni-edi # Q160302
grep "Glasgow Univ" educated > working/uni-gla # Q192775
grep "Aberdeen Univ" educated > working/uni-aber # Q270532
grep "St. Andrews Univ" educated > working/uni-stan # Q216273
grep "Trinity, Dublin" educated > working/uni-tcd # Q258464

# and the Inns

grep "M. Temple" educated > working/inn-m-temple # Q925942
grep "I. Temple" educated > working/inn-i-temple # Q1233784
grep "L. Inn" educated > working/inn-l # Q69482
grep "L.Inn" educated >> working/inn-l # Q69482 
grep "G. Inn" educated > working/inn-g # Q157412
grep "Kingâ€™s Inn" educated > working/inn-king # Q2069586
grep "King's Inn" educated >> working/inn-king # Q2069586

# now we have a lot of extracted people, we can build an index and upload away

# constrained as ONLY ETON for now

curl "http://tools.wmflabs.org/wikidata-todo/beacon.php?prop=1614&source=0" | sed 's/||/\t/g' > working/beacon

for i in `cat working/school-eton | cut -f 1 | sed 's/.html//g'` ; do grep $i working/beacon >> working/list-eton ; done

# list of all Q-ids and corresponding slugs for etonians

# now find only one for each - the use of tail is to ensure it's the later volume as standard (consistent with other uses)

for i in `cat working/list-eton | cut -f 1 | sort | uniq` ; do grep $i working/list-eton | tail -n 1 >> working/trimmedlist-eton ; done

# now build the QuickStatements line
# for now, this only uses a simple referenceURL cite

rm quickstatements

for i in `cat working/trimmedlist-eton` ; do

echo -e `echo $i | cut -f 1`"\t"P69"\t"Q192088"\t"S854"\t""\"http://www.historyofparliamentonline.org/volume/"`echo $i | cut -f 2`\" >> quickstatements ;

done






# important - this will need SOME KIND of do-not-duplicate check before being used - we don't want to keep spamming in the same statements, with or without references
