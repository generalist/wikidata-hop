#!/bin/bash

# script for extracting various metadata from HoP HTML pages and preparing for Wikidata

# nb this needs them all in a handy directory at eg 1386-1421/member/xyz.html

# uses pup - https://github.com/ericchiang/pup

# refresh with 
# curl "https://raw.githubusercontent.com/generalist/wikidata-hop/master/hopextract" > hopextract

rm working/*

#echo "1386-1421" > working/period
#echo "1509-1558" >> working/period
#echo "1558-1603" >> working/period
#echo "1604-1629" >> working/period
#echo "1660-1690" >> working/period
#echo "1690-1715" >> working/period
#echo "1715-1754" >> working/period
#echo "1754-1790" >> working/period
echo "1790-1820" >> working/period
echo "1820-1832" >> working/period

# let's do this across all MPs, ever
# however, comment it out to only the completed ones for now

rm educated

for j in `cat working/period` ; do

# produce a raw list of the educated section

for i in `ls $j/member/*.html` ; do echo -e $i "\t" `cat $i | pup --color | grep -A 2 "educ$" | tail -1` >> educated ; done
for i in `ls $j/member/*.html` ; do echo -e $i "\t" `cat $i | pup --color | grep -A 2 "educ.$" | tail -1` >> educated ; done
# these are the two forms used

done

# pull out the schools (just schools for now as proof of concept)

grep "Eton" educated > working/school-eton # Q192088
grep "Harrow" educated > working/school-harrow # Q1247373
grep "Rugby" educated > working/school-rugby # Q1143281
grep "Westminster" educated > working/school-westminster # Q1341516

